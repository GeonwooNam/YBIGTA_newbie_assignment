## LLM 과제 보고서
### 작성자: 28기 남건우

## 1. 각 Prompting의 0/3/5 shot 정답률
| | 0 shot | 3 shot | 5 shot |
|---|--------|---|---|
|direct prompting | 0.80   | 0.76 | 0.78|
|CoT prompting| 0.88   | 0.72 | 0.78 |
|My prompting | 0.88   | | |

## 2. CoT Prompting이 Direct Prompting에 비해 왜 좋을 수 있는지
1. 추론의 분해와 작업 기억 확보: Direct Prompting은 질문과 정답 사이의 직접적인 매핑만을 수행하므로, 중간 단계가 많은 수학 문제에서 논리적 비약이 발생하기 쉽습니다. 반면 CoT는 문제를 작은 단위의 하위 문제로 분해하여 단계별로 처리하게 함으로써 모델에게 일종의 '작업 기억(Working Memory)' 공간을 제공합니다.
2. 연산 자원의 효율적 활용: CoT는 모델이 정답을 내뱉기 전 더 많은 토큰을 생성하게 유도합니다. 이는 모델이 논리적인 연산을 수행할 수 있는 '연산 시간'을 벌어주는 효과를 가져오며, 특히 모델의 규모가 커질수록 이러한 추론 유도 효과는 비약적으로 상승합니다.
3. 오류 추적 가능성: Direct Prompting은 정답이 틀렸을 때 모델이 어디서 잘못 생각했는지 알 수 없습니다. CoT는 추론 과정을 가시화하므로 사용자가 모델의 논리적 결함을 파악하고 프롬프트를 수정할 수 있는 피드백 루프를 제공합니다.

## 3. 제가 작성한 프롬프트 기법이 CoT에 비해서 왜 더 좋을 수 있는지
1. 프롬프트 상으로는 CoT를 기반으로 하되 correction 즉 정답 검증을 넣었고 rethinking 방지 문구를 통해 무한 루프를 막았습니다.
2. few shot example을 선정하는데 많은 공을 들였습니다. 기본적인 아이디어는 다음과 같습니다.
    ```text
   1. LLM이 question을 보고 CoT로 풀어봄 (0 shot). 풀이과정도 서술함
   2. question, 정답(풀이과정 포함), LLM의 답변(풀이과정 포함), 정답 여부를 바탕으로 각 문제의 난이도를 1~5등급으로 나눔
   3. few shot에 다양한 등급의 문제를 넣음
    ```
   처음에는 오답에 대해서 2번을 수행하고 few shot으로 난이도가 제일 어려운 문제들을 넣으려고 하였으나, 수행 결과 오히려 쉬운 문제에 대해 overthinking을 하면서 성능 저하를 불러왔습니다. 이에 정답까지 포함하여 다양한 난이도의 문제를 few shot example에 넣어 예시의 다양성을 확보하고 다양한 문제에 대한 각각의 대처법을 제시했습니다.
